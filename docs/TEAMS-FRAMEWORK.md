# Teams Framework - OrquestraÃ§Ã£o Multi-Agente

## ğŸ¯ Conceitos Fundamentais

### DefiniÃ§Ãµes

**Persona/Agent Definition (DefiniÃ§Ã£o)**
- Arquivo GUIDE.md descrevendo expertise, background, responsabilidades
- Define "quem Ã©" o agente e "o que sabe fazer"
- ContÃ©m frameworks, checklists, exemplos
- Exemplo: `backend-validator/GUIDE.md`

**Worker/Agent Instance (InstÃ¢ncia)**
- ExecuÃ§Ã£o paralela de uma tarefa usando Task tool
- Pode usar uma persona definida ou ser genÃ©rico
- MÃºltiplos workers podem rodar simultaneamente
- Exemplo: `Task(subagent_type="general-purpose", prompt="You are backend-validator...")`

**Team (Equipe)**
- OrganizaÃ§Ã£o estruturada de mÃºltiplos agentes/workers
- CoordenaÃ§Ã£o sequencial ou paralela para resolver problema complexo
- Define workflow de comunicaÃ§Ã£o entre agentes
- Pode ter mÃºltiplas rodadas de interaÃ§Ã£o

---

## ğŸ—ï¸ Arquiteturas de Teams

### 1. Sequential Team (Equipe Sequencial)

**Quando usar**: Etapas dependem de resultados anteriores

**Estrutura**:
```
User Request
    â†“
[Agent 1: Analysis] â†’ Results 1
    â†“
[Agent 2: Design] â†’ Results 2
    â†“
[Agent 3: Implementation] â†’ Results 3
    â†“
[Agent 4: Validation] â†’ Final Output
```

**Exemplo - Feature Development Team**:
```markdown
1. tech-lead-coordinator: Analisa requisitos, identifica riscos
   â†’ Output: Architectural decisions, risk assessment

2. backend-validator: Valida design do backend
   â†’ Input: Architectural decisions
   â†’ Output: Backend implementation plan

3. frontend-validator: Valida design do frontend
   â†’ Input: Architectural decisions
   â†’ Output: Frontend implementation plan

4. tech-lead-coordinator: Review final
   â†’ Input: Both implementation plans
   â†’ Output: Go/No-go decision
```

**ImplementaÃ§Ã£o**:
```
Round 1: Analysis
- Call Task(tech-lead-coordinator)
- Wait for results

Round 2: Parallel validation
- Single message with TWO Task calls
- Wait for both

Round 3: Final review
- Call Task(tech-lead-coordinator)
```

---

### 2. Parallel Team (Equipe Paralela)

**Quando usar**: Tarefas independentes que podem rodar simultaneamente

**Estrutura**:
```
User Request
    â†“
    â”œâ”€â†’ [Agent 1: Task A] â”€â†’ Result A
    â”œâ”€â†’ [Agent 2: Task B] â”€â†’ Result B
    â”œâ”€â†’ [Agent 3: Task C] â”€â†’ Result C
    â””â”€â†’ [Agent 4: Task D] â”€â†’ Result D
    â†“
[Coordinator: Synthesis] â†’ Final Output
```

**Exemplo - Multi-File Validation Team**:
```markdown
Parallel validation of multiple files:
1. backend-validator: Validates routes/commands.ts
2. backend-validator: Validates routes/history.ts
3. backend-validator: Validates services/golfleet.ts
4. frontend-validator: Validates hooks/useCommands.ts

After all complete:
5. tech-lead-coordinator: Synthesizes all findings
```

**ImplementaÃ§Ã£o**:
```
Single message with MULTIPLE Task calls:
- All 4 validators run in parallel
- Wait for all to complete
- Then call tech-lead-coordinator for synthesis
```

---

### 3. Hierarchical Team (Equipe HierÃ¡rquica)

**Quando usar**: Problema complexo com sub-problemas

**Estrutura**:
```
[Coordinator/Manager]
    â†“
    â”œâ”€â†’ [Team Lead 1]
    â”‚       â”œâ”€â†’ [Worker A]
    â”‚       â””â”€â†’ [Worker B]
    â”œâ”€â†’ [Team Lead 2]
    â”‚       â”œâ”€â†’ [Worker C]
    â”‚       â””â”€â†’ [Worker D]
    â””â”€â†’ [Quality Assurance]
    â†“
Final Output
```

**Exemplo - Full Sprint Implementation Team**:
```markdown
1. tech-lead-coordinator (Manager): Breaks down sprint into tasks
   â†’ Output: Task list with dependencies

2. Backend Team (backend-validator leads):
   - Spawns workers for routes, services, tests
   â†’ Output: Backend implementation complete

3. Frontend Team (frontend-validator leads):
   - Spawns workers for hooks, components, tests
   â†’ Output: Frontend implementation complete

4. Integration Team (tech-lead-coordinator):
   - Reviews both implementations
   - Runs integration tests
   â†’ Output: Sprint complete
```

---

### 4. Iterative Team (Equipe Iterativa)

**Quando usar**: Problema requer refinamento progressivo

**Estrutura**:
```
[Agent 1: Generator] â†’ Draft v1
    â†“
[Agent 2: Critic] â†’ Feedback v1
    â†“
[Agent 1: Generator] â†’ Draft v2
    â†“
[Agent 2: Critic] â†’ Feedback v2
    â†“
... (atÃ© convergÃªncia)
    â†“
Final Output
```

**Exemplo - API Design Refinement Team**:
```markdown
Round 1:
- api-debugger: Analyzes Postman + Python script, proposes endpoint design
- backend-validator: Reviews design, identifies issues

Round 2 (if issues found):
- api-debugger: Refines design based on feedback
- backend-validator: Re-validates

Continue until backend-validator approves
```

---

### 5. Hub-and-Spoke Team (Equipe Estrela)

**Quando usar**: Coordenador central precisa consultar mÃºltiplos especialistas

**Estrutura**:
```
        [Specialist 1]
             â†“
        [Specialist 2] â†â†’ [Hub/Coordinator] â†â†’ [Specialist 4]
             â†“
        [Specialist 3]
             â†“
        Final Decision
```

**Exemplo - Pre-Deployment Review Team**:
```markdown
Hub: tech-lead-coordinator asks questions to specialists

Round 1 (Parallel queries):
- backend-validator: Is backend production-ready?
- frontend-validator: Is frontend production-ready?
- test-specialist: Is test coverage sufficient?
- ui-specialist: Is UI polished?

Hub receives all answers, identifies gaps

Round 2 (If gaps, targeted follow-ups):
- backend-validator: Fix critical issue X
- Hub waits for fix

Round 3 (Final check):
- Hub makes go/no-go decision
```

---

## ğŸ“‹ Team Patterns por Tipo de Tarefa

### Feature Development
**Pattern**: Sequential â†’ Parallel â†’ Sequential
```
1. tech-lead: Plan architecture (Sequential)
2. backend-validator + frontend-validator: Validate designs (Parallel)
3. Implement code (Human or AI)
4. backend-validator + frontend-validator: Validate implementations (Parallel)
5. tech-lead: Final review (Sequential)
```

### Bug Investigation
**Pattern**: Parallel â†’ Sequential
```
1. Multiple agents investigate different areas (Parallel):
   - backend-validator: Check API logs
   - frontend-validator: Check browser console
   - ux-specialist: Reproduce bug flow
2. tech-lead: Synthesize findings, identify root cause (Sequential)
3. Relevant validator: Verify fix (Sequential)
```

### Code Review
**Pattern**: Parallel â†’ Hierarchical
```
1. Multiple validators review different aspects (Parallel):
   - backend-validator: Security, performance
   - frontend-validator: Accessibility, UX
   - test-specialist: Test coverage
2. tech-lead: Aggregate feedback, prioritize (Hierarchical)
```

### API Debugging
**Pattern**: Sequential â†’ Iterative
```
1. api-debugger: Compare implementations (Sequential)
2. Iterative refinement:
   - api-debugger: Proposes fix
   - backend-validator: Validates fix
   - Repeat until approved
```

---

## ğŸ› ï¸ ImplementaÃ§Ã£o PrÃ¡tica

### Exemplo Real: Sprint 3 Command Sending (O que fizemos)

**Team usado**: Sequential â†’ Parallel (Iterative)

**Round 1 - Problem Analysis (Sequential)**:
```
User reported: "Buttons redirect to login instead of sending commands"

Action: Created ux-specialist agent
Called: Task(ux-specialist, "analyze authentication bug")
Result: Identified race conditions in token storage
```

**Round 2 - Layout Issues (Parallel)**:
```
User reported: "Layout has issues - margins, scroll, etc"

Action: Created ui-specialist agent
Called TWO Tasks in parallel:
- Task(ui-specialist, "analyze layout issues")
- Task(ux-specialist, "analyze user flow")

Result: Both identified AppLayout.tsx as root cause
```

**Round 3 - API Issues (Iterative)**:
```
User: "Commands still fail with 403"

Round 3a:
- Called: Task(backend-validator, "investigate 403 errors")
- Result: Found AWS API Gateway issue

Round 3b (after first fix failed):
- Created: api-debugger agent
- Called: Task(api-debugger, "compare Postman + Python + implementation")
- Result: Found THREE critical issues (endpoint, Bearer, casing)

Round 3c (verification):
- Applied fixes
- Ready for user testing
```

**Team Effectiveness**:
- âœ… ui-specialist: Found root cause of layout in 1 try
- âœ… api-debugger: Found ALL 3 API issues in 1 comprehensive analysis
- âœ… Avoided going in circles by using specialized agents

---

## ğŸ“ Workflow Decision Tree

```
New Task Arrives
    â†“
Is it exploratory/research?
    â”œâ”€ YES â†’ Use Explore agent (single agent)
    â””â”€ NO â†“

Does it have multiple independent subtasks?
    â”œâ”€ YES â†’ Parallel Team
    â””â”€ NO â†“

Does it require iterative refinement?
    â”œâ”€ YES â†’ Iterative Team
    â””â”€ NO â†“

Does it have sequential dependencies?
    â”œâ”€ YES â†’ Sequential Team
    â””â”€ NO â†“

Is there a coordinating agent + specialists?
    â”œâ”€ YES â†’ Hub-and-Spoke Team
    â””â”€ NO â†“

Are you UNCERTAIN which pattern to use?
    â”œâ”€ YES â†’ ASK USER for guidance
    â”‚         User can suggest or delegate decision
    â””â”€ NO â†’ Single specialized agent
```

**âš ï¸ IMPORTANT - When Uncertain About Team Pattern**:

**ALWAYS validate with user when uncertain**. Present options clearly:
- "I see this could be [Pattern A] because [reason] or [Pattern B] because [reason]. Which would you prefer?"
- "This task seems to need [Pattern X]. Does that sound right, or would you suggest a different approach?"
- User can either:
  - Provide specific guidance ("Use Pattern A")
  - Suggest alternative approach ("Actually, try Pattern C")
  - Delegate decision back ("Your call, go with what makes sense")

**Never assume** when multiple patterns could work. User context often reveals the best choice.

---

## ğŸ“ LiÃ§Ãµes Aprendidas (Sprint 3)

### O que funcionou bem:
1. **Criar agentes especializados antes de trabalhar**
   - api-debugger encontrou todos os issues em 1 anÃ¡lise
   - ui-specialist/ux-specialist separaram concerns claramente

2. **Executar validaÃ§Ãµes em paralelo**
   - Economiza tempo
   - Cada agente foca em sua expertise

3. **IteraÃ§Ã£o com feedback**
   - api-debugger â†’ backend-validator loop
   - Cada round refinava a soluÃ§Ã£o

### O que evitar:
1. **Trabalhar diretamente sem agentes**
   - Rodamos em cÃ­rculos tentando fixes sem anÃ¡lise estruturada
   - Perdemos contexto com mÃºltiplas tentativas

2. **NÃ£o documentar decisÃµes dos agentes**
   - Importante salvar outputs para referÃªncia futura

3. **Ignorar a necessidade de novos agentes**
   - api-debugger sÃ³ foi criado depois de vÃ¡rias tentativas
   - Deveria ter sido criado no primeiro 403 error

---

## ğŸ“ Templates de Chamadas

### Template: Parallel Validation Team
```
# Objetivo: Validar mÃºltiplos arquivos modificados

Round 1 - Parallel Execution:
Send ONE message with MULTIPLE Task calls:

Task 1: backend-validator validates file A
Task 2: backend-validator validates file B
Task 3: frontend-validator validates file C
Task 4: test-specialist validates test coverage

Wait for all 4 to complete.

Round 2 - Synthesis:
Task: tech-lead-coordinator
Prompt: "Review all 4 validation reports. Prioritize issues. Create action plan."
```

### Template: Iterative Refinement Team
```
# Objetivo: Refinar soluÃ§Ã£o atÃ© aprovaÃ§Ã£o

Round 1:
- specialist-A: Proposes solution
- Wait for output

Round 2:
- specialist-B: Reviews solution from Round 1
- If approved â†’ Done
- If issues â†’ Continue to Round 3

Round 3:
- specialist-A: Refines based on Round 2 feedback
- Go back to Round 2

Max 3-5 iterations, then escalate to human.
```

### Template: Hub-and-Spoke Review
```
# Objetivo: Pre-deployment checklist

Round 1 - Parallel Queries:
Send ONE message with ALL specialist calls:
- backend-validator: Production readiness?
- frontend-validator: UX/Accessibility ready?
- test-specialist: Coverage sufficient?
- ui-specialist: Visual polish done?

Round 2 - Coordinator Decision:
Task: tech-lead-coordinator
Input: All 4 reports from Round 1
Output: Go/No-go + action items if No-go

If No-go:
Round 3 - Targeted Fixes:
- Address specific issues
- Re-validate with relevant specialist
- Return to Round 2
```

---

## ğŸ”„ Integration com CLAUDE.md

A documentaÃ§Ã£o em `.claude/CLAUDE.md` deve referenciar este framework:

```markdown
## ğŸ¤– CRITICAL: Agent-First Development

**Workflow**:
1. Identify task type
2. Check `.claude/docs/TEAMS-FRAMEWORK.md` for appropriate team pattern
3. Create any missing agent definitions
4. Execute team workflow
5. Synthesize results

**Team Patterns**: See `TEAMS-FRAMEWORK.md` for:
- Sequential Teams
- Parallel Teams
- Hierarchical Teams
- Iterative Teams
- Hub-and-Spoke Teams
```

---

## âœ… Checklist de Uso de Teams

Antes de executar qualquer tarefa complexa:

- [ ] Identifiquei o tipo de tarefa?
- [ ] Consultei TEAMS-FRAMEWORK.md para pattern apropriado?
- [ ] Verifiquei quais agent personas existem em `.claude/agents/`?
- [ ] Criei novos agents se necessÃ¡rio?
- [ ] Defini ordem de execuÃ§Ã£o (paralelo vs sequencial)?
- [ ] Planejei quantas rounds de interaÃ§Ã£o esperar?
- [ ] Defini critÃ©rios de sucesso/convergÃªncia?

Durante execuÃ§Ã£o:

- [ ] Estou salvando outputs dos agents para referÃªncia?
- [ ] Estou sintetizando resultados entre rounds?
- [ ] Estou respeitando o mÃ¡ximo de 3-5 iterations antes de escalar?

ApÃ³s conclusÃ£o:

- [ ] Documentei qual team pattern foi usado?
- [ ] Documentei o que funcionou/nÃ£o funcionou?
- [ ] Atualizei agent personas se aprendi algo novo?

---

## ğŸ¯ PrÃ³ximos Passos

1. **Atualizar CLAUDE.md** com referÃªncia a este framework
2. **Criar templates prÃ¡ticos** de team workflows mais usados
3. **Documentar mÃ©tricas** de efetividade de cada pattern
4. **Revisar sprints futuros** usando team patterns

---

**VersÃ£o**: 1.0
**Ãšltima atualizaÃ§Ã£o**: 2026-01-16
**Autor**: Luis Romano + Claude Sonnet 4.5
